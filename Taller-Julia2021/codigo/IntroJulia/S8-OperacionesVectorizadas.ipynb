{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paralelismo en Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia proporciona distintos mecanismos para paralelizar código. Algunas de las estrategias y desafíos para escribir algoritmos paralelos son los siguientes:  \n",
    "\n",
    "* Estrategias de paralelismo\n",
    "     * SIMD\n",
    "     * Multi-hilo\n",
    "     * Tareas\n",
    "     * Multiproceso\n",
    "         * Memoria compartida\n",
    "         * Memoria distribuida\n",
    "     * Programación de GPU\n",
    "\n",
    "* Desafíos de la computación paralela\n",
    "     * Orden de ejecución\n",
    "         * ejecución de fuera de orden de posibilidad\n",
    "         * acceso y mutación simultáneos\n",
    "     * Acceso y movimiento de datos\n",
    "     * Código de acceso y movimiento\n",
    "     * Adaptación adecuada de la estrategia de paralelismo a las capacidades de su máquina\n",
    "     * Hacer coincidir adecuadamente la estrategia de paralelismo con el problema en cuestión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es lo que está sucediendo con nuestras computadoras?\n",
    "\n",
    "![](https://raw.githubusercontent.com/JuliaComputing/JuliaAcademyData.jl/master/courses/Parallel_Computing/images/40-years-processor-trend.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lo difícil de la computación paralela\n",
    "   * No pensamos en paralelo\n",
    "   * Aprendemos a escribir y razonar sobre programas en serie.\n",
    "   * El deseo de paralelismo a menudo surge _después_ de haber escrito su algoritmo (¡y lo encontró demasiado lento!)\n",
    "\n",
    "## Resumen:\n",
    "   * Las arquitecturas computacionales actuales nos empujan hacia la programación paralela para un rendimiento máximo, ¡incluso si no estamos en un clúster!\n",
    "   * Pero es difícil diseñar buenos algoritmos paralelos\n",
    "   * Es difícil de expresar y razonar sobre esos algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SIMD: El paralelismo que puede (a veces) suceder automáticamente\n",
    "\n",
    "SIMD: Instrucción única, datos múltiples (Single Instruction Multiple Data)\n",
    "\n",
    "**Nota:** También llamado confusamente vectorización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquitectura\n",
    "\n",
    "En lugar de calcular cuatro sumas secuencialmente:\n",
    "\n",
    "\\begin{align}\n",
    "x_1 + y_1 &\\rightarrow z_1 \\\\\n",
    "x_2 + y_2 &\\rightarrow z_2 \\\\\n",
    "x_3 + y_3 &\\rightarrow z_3 \\\\\n",
    "x_4 + y_4 &\\rightarrow z_4\n",
    "\\end{align}\n",
    "\n",
    "Procesadores modernos tienen unidades de procesamiento vectorial que pueden hacer lo anterior a la vez:\n",
    "\n",
    "$$\n",
    "\\left(\\begin{array}{cc}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3 \\\\\n",
    "x_4\n",
    "\\end{array}\\right)\n",
    "+\n",
    "\\left(\\begin{array}{cc}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "y_3 \\\\\n",
    "y_4\n",
    "\\end{array}\\right)\n",
    "\\rightarrow\n",
    "\\left(\\begin{array}{cc}\n",
    "z_1 \\\\\n",
    "z_2 \\\\\n",
    "z_3 \\\\\n",
    "z_4\n",
    "\\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo se logra?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50154.62310354247"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = rand(100_000)\n",
    "function simplesum(A)\n",
    "    result = zero(eltype(A))\n",
    "    for i in eachindex(A)\n",
    "        @inbounds result += A[i]\n",
    "    end\n",
    "    return result\n",
    "end\n",
    "\n",
    "simplesum(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como muchos lenguajes de programación modernos, Julia utiliza la verificación de límites ([_boundchecking_](https://docs.julialang.org/en/v1/devdocs/boundscheck/)) para garantizar la seguridad del programa al acceder a arreglos.\n",
    "En bucles internos u otras situaciones críticas de rendimiento, es posible que se desee omitir estas comprobaciones de límites para mejorar el rendimiento en tiempo de ejecución.\n",
    "\n",
    "En consecuencia, Julia incluye la macro `@inbounds(...)` para decirle al compilador que omita dichas comprobaciones de límites dentro del bloque dado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  143.232 μs (0 allocations: 0 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50154.62310354247"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime simplesum($A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿ese tiempo es bueno?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  17.611 μs (0 allocations: 0 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50154.62310354205"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime sum($A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diseñamos una función más lenta que la suma prediseñada `sum()`, ¡y también estamos obteniendo una respuesta diferente! Veamos qué sucede con un flotante de 32 bits en lugar de uno de 64 bits. Cada elemento tiene la mitad del número de bits, por lo que también permite duplicar la longitud (para que el número total de bits procesados permanezca constante)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  286.429 μs (0 allocations: 0 bytes)\n",
      "  19.587 μs (0 allocations: 0 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99875.3f0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A32 = rand(Float32, length(A)*2)\n",
    "@btime simplesum($A32)\n",
    "@btime sum($A32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Eso es aun peor! ¿Que está pasando aqui? \n",
    "Estamos viendo múltiples diferencias en el desempeño: ¿quizás la suma incorporada de Julia está usando algún paralelismo?\n",
    "\n",
    "Intentemos usar SIMD nosotros mismos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  16.293 μs (0 allocations: 0 bytes)\n",
      "  16.354 μs (0 allocations: 0 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99875.305f0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function simdsum(A)\n",
    "    result = zero(eltype(A))\n",
    "    @simd for i in eachindex(A)\n",
    "        @inbounds result += A[i]\n",
    "    end\n",
    "    return result\n",
    "end\n",
    "@btime simdsum($A)\n",
    "@btime simdsum($A32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué hizo y por qué no siempre usamos (usa Julia pues) `@simd` para cada bucle **for** automáticamente?\n",
    "\n",
    "Veamos los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50008.443227500014, 50008.44322750009, 50008.443227500095)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplesum(A), simdsum(A), sum(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99940.69f0, 99940.2f0, 99940.19f0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplesum(A32), simdsum(A32), sum(A32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Por qué no son iguales?\n",
    "\n",
    "Sin `@simd`, Julia está haciendo _exactamente_ lo que le dijimos que hiciera: está tomando cada elemento de nuestro arreglo y lo agrega a una gran pila secuencialmente. Nuestra respuesta es más pequeña de lo que la \"suma\" incorporada de Julia cree que es: eso es porque, como la pila se hace más grande, comenzamos a perder las partes inferiores de cada elemento que estamos sumando, ¡y esas pequeñas pérdidas comienzan a acumularse!\n",
    "\n",
    "La macro `@simd` le dice a Julia que puede reorganizar las adiciones de punto flotante -\n",
    "incluso si cambiara la respuesta. Dependiendo de su CPU, esto puede llevar a 2x o 4x\n",
    "o incluso un paralelismo 8x. Básicamente, Julia está calculando sumas independientes para\n",
    "los índices pares y los índices impares simultáneamente:\n",
    "\n",
    "\\begin{align}\n",
    "odds &\\leftarrow 0 \\\\\n",
    "evens &\\leftarrow 0 \\\\\n",
    "\\text{loop}&\\ \\text{odd}\\ i: \\\\\n",
    "    &\\left(\\begin{array}{cc}\n",
    "odds \\\\\n",
    "evens\n",
    "\\end{array}\\right)\n",
    "\\leftarrow\n",
    "\\left(\\begin{array}{cc}\n",
    "odds \\\\\n",
    "evens\n",
    "\\end{array}\\right)\n",
    "+\n",
    "\\left(\\begin{array}{cc}\n",
    "x_{i} \\\\\n",
    "x_{i+1}\n",
    "\\end{array}\\right) \\\\\n",
    "total &\\leftarrow evens + odds\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "En muchos casos, Julia puede y sabe que un bucle for puede ser vectorizado (SIMD-ed) y aprovechará esto por defecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  16.291 μs (0 allocations: 0 bytes)\n",
      "  17.251 μs (0 allocations: 0 bytes)\n",
      "  16.338 μs (0 allocations: 0 bytes)\n",
      "  16.333 μs (0 allocations: 0 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1101303"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = rand(1:10, 100_000)\n",
    "@btime simplesum($B)\n",
    "@btime sum($B)\n",
    "B32 = rand(Int32(1):Int32(10), length(B)*2)\n",
    "@btime simplesum($B32)\n",
    "@btime simdsum($B32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo inspeccionamos que se está vectorizando?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ";  @ In[25]:2 within `simdsum'\n",
      "define float @julia_simdsum_18131(%jl_value_t addrspace(10)* nonnull align 16 dereferenceable(40)) {\n",
      "top:\n",
      ";  @ In[25]:3 within `simdsum'\n",
      "; ┌ @ simdloop.jl:69 within `macro expansion'\n",
      "; │┌ @ abstractarray.jl:212 within `eachindex'\n",
      "; ││┌ @ abstractarray.jl:95 within `axes1'\n",
      "; │││┌ @ abstractarray.jl:75 within `axes'\n",
      "; ││││┌ @ array.jl:155 within `size'\n",
      "       %1 = addrspacecast %jl_value_t addrspace(10)* %0 to %jl_value_t addrspace(11)*\n",
      "       %2 = bitcast %jl_value_t addrspace(11)* %1 to %jl_value_t addrspace(10)* addrspace(11)*\n",
      "       %3 = getelementptr inbounds %jl_value_t addrspace(10)*, %jl_value_t addrspace(10)* addrspace(11)* %2, i64 3\n",
      "       %4 = bitcast %jl_value_t addrspace(10)* addrspace(11)* %3 to i64 addrspace(11)*\n",
      "       %5 = load i64, i64 addrspace(11)* %4, align 8\n",
      "; ││││└\n",
      "; ││││┌ @ tuple.jl:157 within `map'\n",
      "; │││││┌ @ range.jl:320 within `OneTo' @ range.jl:311\n",
      "; ││││││┌ @ promotion.jl:409 within `max'\n",
      "         %6 = icmp sgt i64 %5, 0\n",
      "         %7 = select i1 %6, i64 %5, i64 0\n",
      "; │└└└└└└\n",
      "; │ @ simdloop.jl:72 within `macro expansion'\n",
      "   br i1 %6, label %L13.lr.ph, label %L30\n",
      "\n",
      "L13.lr.ph:                                        ; preds = %top\n",
      "   %8 = bitcast %jl_value_t addrspace(11)* %1 to float addrspace(13)* addrspace(11)*\n",
      "   %9 = load float addrspace(13)*, float addrspace(13)* addrspace(11)* %8, align 8\n",
      "; │ @ simdloop.jl:75 within `macro expansion'\n",
      "   %min.iters.check = icmp ult i64 %7, 32\n",
      "   br i1 %min.iters.check, label %scalar.ph, label %vector.ph\n",
      "\n",
      "vector.ph:                                        ; preds = %L13.lr.ph\n",
      "   %n.vec = and i64 %7, 9223372036854775776\n",
      "   br label %vector.body\n",
      "\n",
      "vector.body:                                      ; preds = %vector.body, %vector.ph\n",
      "; │ @ simdloop.jl:78 within `macro expansion'\n",
      "; │┌ @ int.jl:53 within `+'\n",
      "    %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]\n",
      "    %vec.phi = phi <8 x float> [ zeroinitializer, %vector.ph ], [ %18, %vector.body ]\n",
      "    %vec.phi10 = phi <8 x float> [ zeroinitializer, %vector.ph ], [ %19, %vector.body ]\n",
      "    %vec.phi11 = phi <8 x float> [ zeroinitializer, %vector.ph ], [ %20, %vector.body ]\n",
      "    %vec.phi12 = phi <8 x float> [ zeroinitializer, %vector.ph ], [ %21, %vector.body ]\n",
      "; │└\n",
      "; │ @ simdloop.jl:77 within `macro expansion' @ In[25]:4\n",
      "; │┌ @ array.jl:788 within `getindex'\n",
      "    %10 = getelementptr inbounds float, float addrspace(13)* %9, i64 %index\n",
      "    %11 = bitcast float addrspace(13)* %10 to <8 x float> addrspace(13)*\n",
      "    %wide.load = load <8 x float>, <8 x float> addrspace(13)* %11, align 4\n",
      "    %12 = getelementptr inbounds float, float addrspace(13)* %10, i64 8\n",
      "    %13 = bitcast float addrspace(13)* %12 to <8 x float> addrspace(13)*\n",
      "    %wide.load13 = load <8 x float>, <8 x float> addrspace(13)* %13, align 4\n",
      "    %14 = getelementptr inbounds float, float addrspace(13)* %10, i64 16\n",
      "    %15 = bitcast float addrspace(13)* %14 to <8 x float> addrspace(13)*\n",
      "    %wide.load14 = load <8 x float>, <8 x float> addrspace(13)* %15, align 4\n",
      "    %16 = getelementptr inbounds float, float addrspace(13)* %10, i64 24\n",
      "    %17 = bitcast float addrspace(13)* %16 to <8 x float> addrspace(13)*\n",
      "    %wide.load15 = load <8 x float>, <8 x float> addrspace(13)* %17, align 4\n",
      "; │└\n",
      "; │┌ @ float.jl:400 within `+'\n",
      "    %18 = fadd fast <8 x float> %vec.phi, %wide.load\n",
      "    %19 = fadd fast <8 x float> %vec.phi10, %wide.load13\n",
      "    %20 = fadd fast <8 x float> %vec.phi11, %wide.load14\n",
      "    %21 = fadd fast <8 x float> %vec.phi12, %wide.load15\n",
      "; │└\n",
      "; │ @ simdloop.jl:78 within `macro expansion'\n",
      "; │┌ @ int.jl:53 within `+'\n",
      "    %index.next = add i64 %index, 32\n",
      "    %22 = icmp eq i64 %index.next, %n.vec\n",
      "    br i1 %22, label %middle.block, label %vector.body\n",
      "\n",
      "middle.block:                                     ; preds = %vector.body\n",
      "; │└\n",
      "; │ @ simdloop.jl:77 within `macro expansion' @ In[25]:4\n",
      "; │┌ @ float.jl:400 within `+'\n",
      "    %bin.rdx = fadd fast <8 x float> %19, %18\n",
      "    %bin.rdx16 = fadd fast <8 x float> %20, %bin.rdx\n",
      "    %bin.rdx17 = fadd fast <8 x float> %21, %bin.rdx16\n",
      "    %rdx.shuf = shufflevector <8 x float> %bin.rdx17, <8 x float> undef, <8 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef>\n",
      "    %bin.rdx18 = fadd fast <8 x float> %bin.rdx17, %rdx.shuf\n",
      "    %rdx.shuf19 = shufflevector <8 x float> %bin.rdx18, <8 x float> undef, <8 x i32> <i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>\n",
      "    %bin.rdx20 = fadd fast <8 x float> %bin.rdx18, %rdx.shuf19\n",
      "    %rdx.shuf21 = shufflevector <8 x float> %bin.rdx20, <8 x float> undef, <8 x i32> <i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>\n",
      "    %bin.rdx22 = fadd fast <8 x float> %bin.rdx20, %rdx.shuf21\n",
      "    %23 = extractelement <8 x float> %bin.rdx22, i32 0\n",
      "    %cmp.n = icmp eq i64 %7, %n.vec\n",
      "; │└\n",
      "; │ @ simdloop.jl:75 within `macro expansion'\n",
      "   br i1 %cmp.n, label %L30, label %scalar.ph\n",
      "\n",
      "scalar.ph:                                        ; preds = %middle.block, %L13.lr.ph\n",
      "   %bc.resume.val = phi i64 [ %n.vec, %middle.block ], [ 0, %L13.lr.ph ]\n",
      "   %bc.merge.rdx = phi float [ %23, %middle.block ], [ 0.000000e+00, %L13.lr.ph ]\n",
      "   br label %L13\n",
      "\n",
      "L13:                                              ; preds = %scalar.ph, %L13\n",
      "   %value_phi16 = phi i64 [ %bc.resume.val, %scalar.ph ], [ %27, %L13 ]\n",
      "   %value_phi5 = phi float [ %bc.merge.rdx, %scalar.ph ], [ %26, %L13 ]\n",
      "; │ @ simdloop.jl:77 within `macro expansion' @ In[25]:4\n",
      "; │┌ @ array.jl:788 within `getindex'\n",
      "    %24 = getelementptr inbounds float, float addrspace(13)* %9, i64 %value_phi16\n",
      "    %25 = load float, float addrspace(13)* %24, align 4\n",
      "; │└\n",
      "; │┌ @ float.jl:400 within `+'\n",
      "    %26 = fadd fast float %value_phi5, %25\n",
      "; │└\n",
      "; │ @ simdloop.jl:78 within `macro expansion'\n",
      "; │┌ @ int.jl:53 within `+'\n",
      "    %27 = add nuw nsw i64 %value_phi16, 1\n",
      "; │└\n",
      "; │ @ simdloop.jl:75 within `macro expansion'\n",
      "; │┌ @ int.jl:49 within `<'\n",
      "    %28 = icmp ult i64 %27, %7\n",
      "; │└\n",
      "   br i1 %28, label %L13, label %L30\n",
      "\n",
      "L30:                                              ; preds = %L13, %middle.block, %top\n",
      "   %value_phi2 = phi float [ 0.000000e+00, %top ], [ %26, %L13 ], [ %23, %middle.block ]\n",
      "; └\n",
      ";  @ In[25]:6 within `simdsum'\n",
      "  ret float %value_phi2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "@code_llvm simdsum(A32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, ¿cuáles son los desafíos?:\n",
    "\n",
    "- El mayor obstáculo es que tienes que convencer a Julia y LLVM de que puede usar instrucciones SIMD para tu algoritmo dado. Eso no siempre es posible.\n",
    "- Hay muchas limitaciones de lo que se puede y no se puede vectorizar\n",
    "- Es necesario pensar en las consecuencias de reordenar su algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen\n",
    "\n",
    "SIMD:\n",
    "- Explota el paralelismo integrado en un procesador\n",
    "- Ideal para bucles internos pequeños (y estrechos)\n",
    "- A menudo ocurre automáticamente si tienes cuidado\n",
    "    - Siga las [mejores prácticas de rendimiento](https://docs.julialang.org/en/v1/manual/performance-tips/)\n",
    "    - Usa `@inbounds` para cualquier acceso a un arreglo\n",
    "    - Evita ramas o llamadas a funciones\n",
    "- Dependiendo del procesador y los tipos involucrados, puede producir ganancias de 2-16x con una sobrecarga extraordinariamente pequeña\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
